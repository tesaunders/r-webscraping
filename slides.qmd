---
title: "Scraping Data From the Web with R"
author: "Tom Saunders Â· Centre for eResearch"
format:
  revealjs:
    theme: dark
    embed-resources: true
    incremental: true
title-slide-attributes: 
  data-background-image: "assets/uoa.png"
  data-background-size: 25%
  data-background-position: 2% 2%
---

## Housekeeping {header=false}

- Audience: Beginner R programmers with no scraping experience.
- This workshop isn't recorded.
- Ask questions in chat at any time.
- Slides are viewable [here](https://tesaunders.github.io/scraping-tutorial/).
- All materials are [here](https://github.com/tesaunders/scraping-tutorial).

## Getting Data from the Web

There are two main ways to collect tabular data from the web:

:::: {.columns}

::: {.column width="50%"}
### 1. Application Programming Interfaces (APIs)

Software interfaces allowing standardised retrieval of data hosted on a server.
:::

::: {.column width="50%}
### 2. Webscraping

Extraction of data directly from webpages via code or specialised software.
:::

::::

## Limitations

- Complex pages don't have tables 'baked in' to them - these will be invisible to R.
- If the page structure or code changes, the scraper will no longer work.
- Some websites will prevent scrapers from working.
- Scraping is legally complex.

## Legal Stuff

Web scraping occupies a complex legal space:

- Website terms of service
- Copyright law
- Privacy laws
- Different jurisdictions

. . .

I'm not a lawyer - use at your own risk, use common sense, and be [polite](https://dmi3kno.github.io/polite/).

## HTML

```
<html>
<head>
  <title>Page title</title>
</head>
<body>
  <h1 id='first'>A heading</h1>
  <p>Some text &amp; <b>some bold text.</b></p>
  <img src='myimg.png' width='100' height='100'>
</body>
```
- Web pages are written in HTML and have a consistent, hierarchical structure.
- HTML elements have a start tag, optional attributes, an end tag, and contents.

## CSS

Cascading Style Sheets define the visual styling of HTML documents (webpages) and are useful for webscraping.

. . .

```
body {
  background-color: powderblue;
}
h1 {
  color: blue;
}
p {
  color: red;
}
```

## Extracting Data

To extract data of interest find the relevant CSS selectors first.

- Right click on an element on the page and click Inspect (Firefox, Chrome, etc). 
- This opens the underlying HTML & CSS code, centered on the element that you just clicked. 
- Explore the page and get a sense of what selectors might work. 
- Pay attention to the class and id attributes.

## 3 Examples

1. Wikipedia: Scraping a table from a page.

1. Carjam: Scraping paginated results by establishing patterns in the URLs.

1. IMDB: Scraping a trickier table & automating it once a week.

## Let's take a look!

## GitHub Actions

[GitHub Actions](https://docs.github.com/en/actions/about-github-actions/understanding-github-actions) allow you to automate a task based on a trigger event.

. . .

For example, researchers can (re)scrape data over time, automatically.

. . .

A *GitHub Actions workflow* is triggered when an *event* occurs in the remote repository. This causes one or more *jobs* to be run, and each job is made up of one or more *steps*.

. . .

A GHA workflow is defined inside a special file which always sits in the `.github/workflows` directory. 

## GitHub Actions: Events & Jobs

Common events that trigger a workflow include:

- A particular schedule (e.g. run once a month)
- When a commit is pushed to a remote repository

. . .

Common steps making up jobs include:

- Run a script
- Build or update a website
- Perform tests on changed files to ensure code is valid

## What Are The Files?

R scripts: 

- `scrape-wiki.r`: Scrapes tables from Wikipedia and joins them together.
- `scrape-carjam`: Scrapes tables from multiple pages of results.
- `scrape-imdb.R`: Scrapes a table and saves as a .csv, once per week, automatically.

. . .

Folders 

- `/data`: folder where data will be saved.
- `/docs`: folder where these slides are published from.

## What Are The Files?

It also contains a GitHub Action defined here:

`/.github/workflows/update.yml`

YAML files contain key:value pairs. You can call the YAML file anything, but the content and structure of the file needs to adhere to a particular [format](https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions). 

## What Are The Files?

- `slides.qmd`: code version of these slides.
- `/assets`: image for title slide.
- `.gitignore`: file created by Git defining which files should be excluded from version control.
- `r-scraping-tutorial.Rproj`: RStudio project file.

## Resources

- [Workshop materials](https://github.com/tesaunders/r-scraping-tutorial)
- [R for Data Science](https://r4ds.hadley.nz/webscraping.html): Go here next.
- [Beginner git lesson](https://uoa-eresearch.github.io/git-novice/): Go here to learn about version control.
- [Happy Git With R](https://happygitwithr.com/): Go here to learn how to use Git/GitHub with RStudio.
- [rvest](https://rvest.tidyverse.org/): R package for webscraping.
- [GitHub Actions](https://docs.github.com/en/actions/about-github-actions/understanding-github-actions)