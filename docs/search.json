[
  {
    "objectID": "slides.html#housekeeping",
    "href": "slides.html#housekeeping",
    "title": "Scraping Data From the Web with R",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nAudience: Beginner R programmers with no scraping experience.\nThis workshop isn’t recorded.\nAsk questions in chat at any time.\nSlides are viewable here.\nAll materials are here."
  },
  {
    "objectID": "slides.html#getting-data-from-the-web",
    "href": "slides.html#getting-data-from-the-web",
    "title": "Scraping Data From the Web with R",
    "section": "Getting Data from the Web",
    "text": "Getting Data from the Web\nThere are two main ways to collect tabular data from the web:\n\n\n1. Application Programming Interfaces (APIs)\nSoftware interfaces allowing standardised retrieval of data hosted on a server.\n\n2. Webscraping\nExtraction of data directly from webpages via code or specialised software."
  },
  {
    "objectID": "slides.html#limitations",
    "href": "slides.html#limitations",
    "title": "Scraping Data From the Web with R",
    "section": "Limitations",
    "text": "Limitations\n\nComplex pages don’t have tables ‘baked in’ to them - these will be invisible to R.\nIf the page structure or code changes, the scraper will no longer work.\nSome websites will prevent scrapers from working.\nScraping is legally complex."
  },
  {
    "objectID": "slides.html#legal-stuff",
    "href": "slides.html#legal-stuff",
    "title": "Scraping Data From the Web with R",
    "section": "Legal Stuff",
    "text": "Legal Stuff\nWeb scraping occupies a complex legal space:\n\nWebsite terms of service\nCopyright law\nPrivacy laws\nDifferent jurisdictions\n\n\nI’m not a lawyer - use at your own risk, use common sense, and be polite."
  },
  {
    "objectID": "slides.html#html",
    "href": "slides.html#html",
    "title": "Scraping Data From the Web with R",
    "section": "HTML",
    "text": "HTML\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Page title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;A heading&lt;/h1&gt;\n  &lt;p&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\n\nWeb pages are written in HTML and have a consistent, hierarchical structure.\nHTML elements have a start tag, optional attributes, an end tag, and contents."
  },
  {
    "objectID": "slides.html#css",
    "href": "slides.html#css",
    "title": "Scraping Data From the Web with R",
    "section": "CSS",
    "text": "CSS\nCascading Style Sheets define the visual styling of HTML documents (webpages) and are useful for webscraping.\n\nbody {\n  background-color: powderblue;\n}\nh1 {\n  color: blue;\n}\np {\n  color: red;\n}"
  },
  {
    "objectID": "slides.html#extracting-data",
    "href": "slides.html#extracting-data",
    "title": "Scraping Data From the Web with R",
    "section": "Extracting Data",
    "text": "Extracting Data\nTo extract data of interest find the relevant CSS selectors first.\n\nRight click on an element on the page and click Inspect (Firefox, Chrome, etc).\nThis opens the underlying HTML & CSS code, centered on the element that you just clicked.\nExplore the page and get a sense of what selectors might work.\nPay attention to the class and id attributes."
  },
  {
    "objectID": "slides.html#lets-take-a-look",
    "href": "slides.html#lets-take-a-look",
    "title": "Scraping Data From the Web with R",
    "section": "Let’s take a look!",
    "text": "Let’s take a look!"
  },
  {
    "objectID": "slides.html#github-actions",
    "href": "slides.html#github-actions",
    "title": "Scraping Data From the Web with R",
    "section": "GitHub Actions",
    "text": "GitHub Actions\nGitHub Actions allow you to automate a task based on a trigger event.\n\nFor example, researchers can (re)scrape data over time, automatically.\n\n\nA GitHub Actions workflow is triggered when an event occurs in the remote repository. This causes one or more jobs to be run, and each job is made up of one or more steps.\n\n\nA GHA workflow is defined inside a special file which always sits in the .github/workflows directory."
  },
  {
    "objectID": "slides.html#github-actions-events-jobs",
    "href": "slides.html#github-actions-events-jobs",
    "title": "Scraping Data From the Web with R",
    "section": "GitHub Actions: Events & Jobs",
    "text": "GitHub Actions: Events & Jobs\nCommon events that trigger a workflow include:\n\nA particular schedule (e.g. run once a month)\nWhen a commit is pushed to a remote repository\n\n\nCommon steps making up jobs include:\n\nRun a script\nBuild or update a website\nPerform tests on changed files to ensure code is valid"
  },
  {
    "objectID": "slides.html#what-are-the-files",
    "href": "slides.html#what-are-the-files",
    "title": "Scraping Data From the Web with R",
    "section": "What Are The Files?",
    "text": "What Are The Files?\nR scripts:\n\nscrape-wiki.r: Scrapes tables from Wikipedia and joins them together.\nscrape-carjam: Scrapes tables from multiple pages of results.\nscrape-imdb.R: Scrapes a table and saves as a .csv, once per week, automatically.\n\n\nFolders\n\n/data: folder where data will be saved.\n/docs: folder where these slides are published from."
  },
  {
    "objectID": "slides.html#what-are-the-files-1",
    "href": "slides.html#what-are-the-files-1",
    "title": "Scraping Data From the Web with R",
    "section": "What Are The Files?",
    "text": "What Are The Files?\nIt also contains a GitHub Action defined here:\n/.github/workflows/update.yml\nYAML files contain key:value pairs. You can call the YAML file anything, but the content and structure of the file needs to adhere to a particular format."
  },
  {
    "objectID": "slides.html#what-are-the-files-2",
    "href": "slides.html#what-are-the-files-2",
    "title": "Scraping Data From the Web with R",
    "section": "What Are The Files?",
    "text": "What Are The Files?\n\nslides.qmd: code version of these slides.\n/assets: image for title slide.\n.gitignore: file created by Git defining which files should be excluded from version control.\nr-scraping-tutorial.Rproj: RStudio project file."
  },
  {
    "objectID": "slides.html#resources",
    "href": "slides.html#resources",
    "title": "Scraping Data From the Web with R",
    "section": "Resources",
    "text": "Resources\n\nWorkshop materials\nR for Data Science: Go here next.\nBeginner git lesson: Go here to learn about version control.\nHappy Git With R: Go here to learn how to use Git/GitHub with RStudio.\nrvest: R package for webscraping.\nGitHub Actions"
  }
]